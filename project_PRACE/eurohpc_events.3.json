[{"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "High-performance scientific computing in C++  (ONLINE)", "url": "https://go.fzj.de/2022-hpc-cplusplus", "description": "Modern C++, with its support for procedural, objected oriented, generic and functional programming styles, offers many powerful abstraction mechanisms to express complexity at a high level while remaining very efficient. It is therefore the language of choice for many scientific projects. The approval of the latest language standard, C++20, has also opened up new abstraction layers and new exciting ways to organize code at all levels. However, achieving high performance by today's standards requires understanding and exploiting multiple levels of parallelism, as well as understanding C++ code from a performance centric viewpoint.\n\nIn this course, the participants will learn how to write C++ programs which better utilize typical HPC hardware resources of the present day. The course is geared towards scientists and engineers already familiar with C++17, who wish to develop maintainable and fast applications. Since C++20 is a relatively large structural change of the C++ language, similar to C++11, novel ways to write expressive, maintainable and fast code are now available to C++ programmers, which will be introduced in the course. The participants will learn techniques to better utilize CPU caches, instruction pipelines, SIMD functionality and multi-threading. Shared memory parallel programming on multiple CPU cores will be introduced using standard C++ parallel STL and Intel (R) Threading Building Blocks. The participants will also learn basic GPGPU programming using C++ template based generic programming techniques.\n\nThis course is a PRACE training course.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-06-07T09:00:00+0200", "startDate": "2022-06-07T09:00:00+0200", "endDate": "2022-06-10T16:30:00+0200", "@id": "https://hpc-portal.eu/node/981", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.fz-juelich.de/SharedDocs/Termine/IAS/JSC/EN/courses/2022/ptc-hpc-cplusplus-2022.html?nn=2800336", "geo": {"@type": "GeoCoordinates", "latitude": "50.909365354514", "longitude": "6.4060157148884"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["PRACE"], "level": ["Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>Modern C++, with its support for procedural, objected oriented, generic and functional programming styles, offers many powerful abstraction mechanisms to express complexity at a high level while remaining very efficient. It is therefore the language of choice for many scientific projects. The approval of the latest language standard, C++20, has also opened up new abstraction layers and new exciting ways to organize code at all levels. However, achieving high performance by today's standards requires understanding and exploiting multiple levels of parallelism, as well as understanding C++ code from a performance centric viewpoint.</p> <p>In this course, the participants will learn how to write C++ programs which better utilize typical HPC hardware resources of the present day. The course is geared towards scientists and engineers already familiar with C++17, who wish to develop maintainable and fast applications. Since C++20 is a relatively large structural change of the C++ language, similar to C++11, novel ways to write expressive, maintainable and fast code are now available to C++ programmers, which will be introduced in the course. The participants will learn techniques to better utilize CPU caches, instruction pipelines, SIMD functionality and multi-threading. Shared memory parallel programming on multiple CPU cores will be introduced using standard C++ parallel STL and Intel (R) Threading Building Blocks. The participants will also learn basic GPGPU programming using C++ template based generic programming techniques.</p> <p>This course is a PRACE training course.</p>", "markdown_description": "Modern C++, with its support for procedural, objected oriented, generic and functional programming styles, offers many powerful abstraction mechanisms to express complexity at a high level while remaining very efficient. It is therefore the language of choice for many scientific projects. The approval of the latest language standard, C++20, has also opened up new abstraction layers and new exciting ways to organize code at all levels. However, achieving high performance by today's standards requires understanding and exploiting multiple levels of parallelism, as well as understanding C++ code from a performance centric viewpoint.\n\nIn this course, the participants will learn how to write C++ programs which better utilize typical HPC hardware resources of the present day. The course is geared towards scientists and engineers already familiar with C++17, who wish to develop maintainable and fast applications. Since C++20 is a relatively large structural change of the C++ language, similar to C++11, novel ways to write expressive, maintainable and fast code are now available to C++ programmers, which will be introduced in the course. The participants will learn techniques to better utilize CPU caches, instruction pipelines, SIMD functionality and multi-threading. Shared memory parallel programming on multiple CPU cores will be introduced using standard C++ parallel STL and Intel (R) Threading Building Blocks. The participants will also learn basic GPGPU programming using C++ template based generic programming techniques.\n\nThis course is a PRACE training course.", "summary": "Modern C++, with its support for procedural, objected oriented, generic and functional programming styles, offers many powerful..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "High-performance computing with Python (ONLINE)", "url": "https://go.fzj.de/2022-hpc-python", "description": "Python is increasingly used in high-performance computing projects. It can be used either as a high-level interface to existing HPC applications and libraries, as embedded interpreter, or directly.\n\nThis course combines lectures and hands-on sessions. We will show how Python can be used on parallel architectures and how to optimize critical parts of the kernel using various tools.\n\nThe following topics will be covered:\n\n  * Interactive parallel programming with IPython\n  * Profiling and optimization\n  * High-performance NumPy\n  * Just-in-time compilation with numba\n  * Distributed-memory parallel programming with Python and MPI\n  * Bindings to other programming languages and HPC libraries\n  * Interfaces to GPUs\n\n\n\nThis course is aimed at scientists who wish to explore the productivity gains made possible by Python for HPC.\n\nThis course is a PRACE training course.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-06-20T09:00:00+0200", "startDate": "2022-06-20T09:00:00+0200", "endDate": "2022-06-24T13:00:00+0200", "@id": "https://hpc-portal.eu/node/982", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://www.fz-juelich.de/SharedDocs/Termine/IAS/JSC/EN/courses/2022/ptc-hpc-python-2022.html?nn=2800336", "geo": {"@type": "GeoCoordinates", "latitude": "50.909405944835", "longitude": "6.4060592285076"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["PRACE"], "level": ["Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>Python is increasingly used in high-performance computing projects. It can be used either as a high-level interface to existing HPC applications and libraries, as embedded interpreter, or directly.</p> <p>This course combines lectures and hands-on sessions. We will show how Python can be used on parallel architectures and how to optimize critical parts of the kernel using various tools.</p> <p>The following topics will be covered:</p> <ul> <li>Interactive parallel programming with IPython</li> <li>Profiling and optimization</li> <li>High-performance NumPy</li> <li>Just-in-time compilation with numba</li> <li>Distributed-memory parallel programming with Python and MPI</li> <li>Bindings to other programming languages and HPC libraries</li> <li>Interfaces to GPUs</li> </ul> <p>This course is aimed at scientists who wish to explore the productivity gains made possible by Python for HPC.</p> <p>This course is a PRACE training course.</p>", "markdown_description": "Python is increasingly used in high-performance computing projects. It can be used either as a high-level interface to existing HPC applications and libraries, as embedded interpreter, or directly.\n\nThis course combines lectures and hands-on sessions. We will show how Python can be used on parallel architectures and how to optimize critical parts of the kernel using various tools.\n\nThe following topics will be covered:\n\n  * Interactive parallel programming with IPython\n  * Profiling and optimization\n  * High-performance NumPy\n  * Just-in-time compilation with numba\n  * Distributed-memory parallel programming with Python and MPI\n  * Bindings to other programming languages and HPC libraries\n  * Interfaces to GPUs\n\n\n\nThis course is aimed at scientists who wish to explore the productivity gains made possible by Python for HPC.\n\nThis course is a PRACE training course.", "summary": "Python is increasingly used in high-performance computing projects. It can be used either as a high-level interface to existing HPC..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Hybrid Programming in HPC - MPI+X", "url": "https://app1.edoobox.com/en/LRZ/Online%20Courses/Online%20Course.ed.2aea539d2ccf_6250920706.Hybrid%20Programming%20in%20HPC%20-%20MPI%2BX%20%28register%20via%20PRACE%29", "description": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.\n\nHands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.\n\nThis online course is a PRACE training event. It is organised by LRZ in cooperation with NHR@FAU, RRZE and the VSC Research Center, TU Wien.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-06-22T09:00:00+0200", "startDate": "2022-06-22T09:00:00+0200", "endDate": "2022-06-24T16:00:00+0200", "@id": "https://hpc-portal.eu/node/1165", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://app1.edoobox.com/en/LRZ/Online%20Courses/Online%20Course.ed.2aea539d2ccf_6250920706.Hybrid%20Programming%20in%20HPC%20-%20MPI%2BX%20%28register%20via%20PRACE%29", "geo": {"@type": "GeoCoordinates", "latitude": "48.261750352317", "longitude": "11.66751545"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["PRACE"], "level": ["Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.</p> <p>Hands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.</p> <p>This online course is a PRACE training event. It is organised by LRZ in cooperation with NHR@FAU, RRZE and the VSC Research Center, TU Wien.</p>", "markdown_description": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.\n\nHands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.\n\nThis online course is a PRACE training event. It is organised by LRZ in cooperation with NHR@FAU, RRZE and the VSC Research Center, TU Wien.", "summary": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time..."}]}]
[{"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Advanced use of LAMMPS", "url": "https://www.archer2.ac.uk/training/courses/220331-adv-lammps/", "description": "This lesson provides an overview of some more advanced techniques and uses of LAMMPS. Specifically, we will be discussing:\n\n  * Measuring and improving LAMMPS performance \n    * Strong vs weak scaling for a range of systems\n    * Smarter domain decomposition\n    * Accelerators and what they do\n  * Using LAMMPS with Python\n  * Analysing systems through reruns\n  * Advanced sampling methods with a focus on replica exchange\n  * Target Audience: \n\n\n\nFor this lesson, we expect attendees to be familiar with LAMMPS. We will not be covering how to prepare and run a parallel LAMMPS simulation (and we will assume that all attendees know how to do this already). This lesson is aimed at anyone who:\n\n  * has experience using bash (or any other shell)\n  * has experience running LAMMPS on multiple processors\n  * would like to learn more about some of the LAMMPS functionalities stated above\n  * would like to learn more about tricks and methods for getting LAMMPS to perform efficiently.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-03-31T11:00:00+0200", "startDate": "2022-03-31T11:00:00+0200", "endDate": "2022-03-31T17:00:00+0200", "@id": "https://hpc-portal.eu/node/1060", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://events.prace-ri.eu/event/1361/registrations/1008/", "geo": {"@type": "GeoCoordinates", "latitude": "55.945302650778", "longitude": "-3.18724045"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["United Kingdom"], "projects": ["PRACE"], "level": ["Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>This lesson provides an overview of some more advanced techniques and uses of LAMMPS. Specifically, we will be discussing:</p> <ul> <li>Measuring and improving LAMMPS performance <ul> <li>Strong vs weak scaling for a range of systems</li> <li>Smarter domain decomposition</li> <li>Accelerators and what they do</li> </ul> </li> <li>Using LAMMPS with Python</li> <li>Analysing systems through reruns</li> <li>Advanced sampling methods with a focus on replica exchange</li> <li> Target Audience: </li> </ul> <p>For this lesson, we expect attendees to be familiar with LAMMPS. We will not be covering how to prepare and run a parallel LAMMPS simulation (and we will assume that all attendees know how to do this already). This lesson is aimed at anyone who:</p> <ul> <li>has experience using bash (or any other shell)</li> <li>has experience running LAMMPS on multiple processors</li> <li>would like to learn more about some of the LAMMPS functionalities stated above</li> <li>would like to learn more about tricks and methods for getting LAMMPS to perform efficiently.</li> </ul>", "markdown_description": "This lesson provides an overview of some more advanced techniques and uses of LAMMPS. Specifically, we will be discussing:\n\n  * Measuring and improving LAMMPS performance \n    * Strong vs weak scaling for a range of systems\n    * Smarter domain decomposition\n    * Accelerators and what they do\n  * Using LAMMPS with Python\n  * Analysing systems through reruns\n  * Advanced sampling methods with a focus on replica exchange\n  * Target Audience: \n\n\n\nFor this lesson, we expect attendees to be familiar with LAMMPS. We will not be covering how to prepare and run a parallel LAMMPS simulation (and we will assume that all attendees know how to do this already). This lesson is aimed at anyone who:\n\n  * has experience using bash (or any other shell)\n  * has experience running LAMMPS on multiple processors\n  * would like to learn more about some of the LAMMPS functionalities stated above\n  * would like to learn more about tricks and methods for getting LAMMPS to perform efficiently.", "summary": "This lesson provides an overview of some more advanced techniques and uses of LAMMPS. Specifically, we will be discussing:\n\n  *..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Introduction to Performance and Energy Efficiency Analysis", "url": "https://events.prace-ri.eu/event/1353/", "description": "The course will offer an introduction to the fundamental concepts of performance, power consumption, and energy efficiency in HPC systems. Then it will focus on the performance analysis process and methodology developed during the POP project, followed by the mechanisms that today's computing elements and systems provide in terms of monitoring and control of power and energy dissipation. Finally, it will introduce and give hands-on sessions for a set of tools for performance analysis as well as reducing the energy consumption in HPC devices.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/edea2a662279be56b230c7221ae33230.webp", "width": 720, "height": 158}, "doorTime": "2022-04-05T09:00:00+0200", "startDate": "2022-04-05T09:00:00+0200", "endDate": "2022-04-05T17:00:00+0200", "@id": "https://hpc-portal.eu/node/845", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://events.prace-ri.eu/event/1353/registrations/999/", "geo": {"@type": "GeoCoordinates", "latitude": "49.837534200979", "longitude": "18.15603595"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Czech Republic"], "projects": ["PRACE"], "level": ["Intermediate"], "online": ["Live (synchronous)"], "html_description": "<p>The course will offer an introduction to the fundamental concepts of performance, power consumption, and energy efficiency in HPC systems. Then it will focus on the performance analysis process and methodology developed during the POP project, followed by the mechanisms that today's computing elements and systems provide in terms of monitoring and control of power and energy dissipation. Finally, it will introduce and give hands-on sessions for a set of tools for performance analysis as well as reducing the energy consumption in HPC devices.</p>", "markdown_description": "The course will offer an introduction to the fundamental concepts of performance, power consumption, and energy efficiency in HPC systems. Then it will focus on the performance analysis process and methodology developed during the POP project, followed by the mechanisms that today's computing elements and systems provide in terms of monitoring and control of power and energy dissipation. Finally, it will introduce and give hands-on sessions for a set of tools for performance analysis as well as reducing the energy consumption in HPC devices.", "summary": "The course will offer an introduction to the fundamental concepts of performance, power consumption, and energy efficiency in HPC..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Hybrid Programming in HPC \u2013 MPI+X", "url": "https://vsc.ac.at/training/2022/HY-VSC", "description": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.\n\nHands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.\n\nContent Levels: Beginners = 0:00h (0%) + Intermediate = 1:30h (10%) + Advanced = 13:30h (90%)\n\nThis course is a PRACE training event.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "tmp_images/9b46fb12976ff7516943e5d305bf9610.webp", "width": 720, "height": 496}, "doorTime": "2022-04-05T09:00:00+0200", "startDate": "2022-04-05T09:00:00+0200", "endDate": "2022-04-07T16:00:00+0200", "@id": "https://hpc-portal.eu/node/920", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://events.prace-ri.eu/event/1337/registrations/990/", "geo": {"@type": "GeoCoordinates", "latitude": "48.1995515", "longitude": "16.3668678"}}, "language": ["English"], "sector": ["Research and Academia", "Industry", "Public Sector", "Other (general public...)"], "country": ["Austria"], "projects": ["PRACE"], "level": ["Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.</p> <p>Hands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.</p> <p>Content Levels: Beginners = 0:00h (0%) + Intermediate = 1:30h (10%) + Advanced = 13:30h (90%)</p> <p>This course is a PRACE training event.</p>", "markdown_description": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time has to be optimized. Therefore, hybrid programming may combine the distributed memory parallelization on the node interconnect (e.g., with MPI) with the shared memory parallelization inside of each node (e.g., with OpenMP or MPI-3.0 shared memory). This course analyzes the strengths and weaknesses of several parallel programming models on clusters of SMP nodes. Multi-socket-multi-core systems in highly parallel environments are given special consideration. MPI-3.0 has introduced a new shared memory programming interface, which can be combined with inter-node MPI communication. It can be used for direct neighbor accesses similar to OpenMP or for direct halo copies, and enables new hybrid programming models. These models are compared with various hybrid MPI+OpenMP approaches and pure MPI. Numerous case studies and micro-benchmarks demonstrate the performance-related aspects of hybrid programming.\n\nHands-on sessions are included on all days. Tools for hybrid programming such as thread/process placement support and performance analysis are presented in a \"how-to\" section. This course provides scientific training in Computational Science and, in addition, the scientific exchange of the participants among themselves.\n\nContent Levels: Beginners = 0:00h (0%) + Intermediate = 1:30h (10%) + Advanced = 13:30h (90%)\n\nThis course is a PRACE training event.", "summary": "Most HPC systems are clusters of shared memory nodes. To use such systems efficiently both memory consumption and communication time..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "Interactive High-Performance Computing with Jupyter (ONLINE)", "url": "https://go.fzj.de/2022-jupyter", "description": "Interactive exploration and analysis of large amounts of data from scientific simulations, in-situ visualization and application control are convincing scenarios for explorative sciences. Based on the open source software Jupyter or JupyterLab, a way has been available for some time now that combines interactive with reproducible computing while at the same time meeting the challenges of support for the wide range of different software workflows.\n\nEven on supercomputers, the method enables the creation of documents that combine live code with narrative text, mathematical equations, visualizations, interactive controls, and other extensive output. However, a number of challenges must be mastered in order to make existing workflows ready for interactive high-performance computing. With so many possibilities, it's easy to lose sight of the big picture. This course provides a detailed introduction to interactive high-performance computing.\n\nThe following topics are covered:\n\n  * Introduction to Jupyter\n  * Parallel computing using Jupyter\n  * Interactive & in-situ visualization\n  * From ipywidgets to dashboards\n\n\n\nThis course is a PRACE training course.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-04-05T09:00:00+0200", "startDate": "2022-04-05T09:00:00+0200", "endDate": "2022-04-07T13:00:00+0200", "@id": "https://hpc-portal.eu/node/979", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://events.prace-ri.eu/event/1338/registrations/991/", "geo": {"@type": "GeoCoordinates", "latitude": "50.909339421723", "longitude": "6.4060758207381"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["PRACE"], "level": ["Beginner", "Intermediate"], "online": ["Live (synchronous)"], "html_description": "<p>Interactive exploration and analysis of large amounts of data from scientific simulations, in-situ visualization and application control are convincing scenarios for explorative sciences. Based on the open source software Jupyter or JupyterLab, a way has been available for some time now that combines interactive with reproducible computing while at the same time meeting the challenges of support for the wide range of different software workflows.</p> <p> Even on supercomputers, the method enables the creation of documents that combine live code with narrative text, mathematical equations, visualizations, interactive controls, and other extensive output. However, a number of challenges must be mastered in order to make existing workflows ready for interactive high-performance computing. With so many possibilities, it's easy to lose sight of the big picture. This course provides a detailed introduction to interactive high-performance computing.</p> <p>The following topics are covered:</p> <ul> <li>Introduction to Jupyter</li> <li>Parallel computing using Jupyter</li> <li>Interactive &amp; in-situ visualization</li> <li>From ipywidgets to dashboards</li> </ul> <p>This course is a PRACE training course.</p>", "markdown_description": "Interactive exploration and analysis of large amounts of data from scientific simulations, in-situ visualization and application control are convincing scenarios for explorative sciences. Based on the open source software Jupyter or JupyterLab, a way has been available for some time now that combines interactive with reproducible computing while at the same time meeting the challenges of support for the wide range of different software workflows.\n\nEven on supercomputers, the method enables the creation of documents that combine live code with narrative text, mathematical equations, visualizations, interactive controls, and other extensive output. However, a number of challenges must be mastered in order to make existing workflows ready for interactive high-performance computing. With so many possibilities, it's easy to lose sight of the big picture. This course provides a detailed introduction to interactive high-performance computing.\n\nThe following topics are covered:\n\n  * Introduction to Jupyter\n  * Parallel computing using Jupyter\n  * Interactive & in-situ visualization\n  * From ipywidgets to dashboards\n\n\n\nThis course is a PRACE training course.", "summary": "Interactive exploration and analysis of large amounts of data from scientific simulations, in-situ visualization and application..."}]}, {"@context": "https://schema.org", "@graph": [{"@type": "Event", "name": "GPU Programming with CUDA (ONLINE)", "url": "https://go.fzj.de/2022-cuda", "description": "GPU-accelerated computing drives current scientific research. Writing fast numeric algorithms for GPUs offers high application performance by offloading compute-intensive portions of the code to an NVIDIA GPU. The course will cover basic aspects of GPU architectures and programming. Focus is on the usage of the parallel programming language CUDA C/C++ which allows maximum control of NVIDIA GPU hardware. Examples of increasing complexity will be used to demonstrate optimization and tuning of scientific applications.\n\nTopics covered will include:\n\n  * Introduction to GPU/Parallel computing\n  * Programming model CUDA\n  * GPU libraries like CuBLAS and CuFFT\n  * Tools for debugging and profiling\n  * Performance optimizations\n  * Advanced GPU programming model\n  * CUDA Fortran in a nutshell\n\n\n\nThis course is a PRACE training course.", "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode", "eventStatus": "https://schema.org/EventScheduled", "image": {"@type": "ImageObject", "representativeOfPage": "True", "url": "images/placeholder.webp", "width": 720, "height": 260}, "doorTime": "2022-04-25T09:00:00+0200", "startDate": "2022-04-25T09:00:00+0200", "endDate": "2022-04-29T13:00:00+0200", "@id": "https://hpc-portal.eu/node/980", "isAccessibleForFree": "True", "location": {"@type": "VirtualLocation", "url": "https://events.prace-ri.eu/event/1341/registrations/994/", "geo": {"@type": "GeoCoordinates", "latitude": "50.909378884625", "longitude": "6.4060588255877"}}, "language": ["English"], "sector": ["Research and Academia", "Industry"], "country": ["Germany"], "projects": ["PRACE"], "level": ["Intermediate", "Advanced"], "online": ["Live (synchronous)"], "html_description": "<p>GPU-accelerated computing drives current scientific research. Writing fast numeric algorithms for GPUs offers high application performance by offloading compute-intensive portions of the code to an NVIDIA GPU. The course will cover basic aspects of GPU architectures and programming. Focus is on the usage of the parallel programming language CUDA C/C++ which allows maximum control of NVIDIA GPU hardware. Examples of increasing complexity will be used to demonstrate optimization and tuning of scientific applications.</p> <p>Topics covered will include:</p> <ul> <li>Introduction to GPU/Parallel computing</li> <li>Programming model CUDA</li> <li>GPU libraries like CuBLAS and CuFFT</li> <li>Tools for debugging and profiling</li> <li>Performance optimizations</li> <li>Advanced GPU programming model</li> <li>CUDA Fortran in a nutshell</li> </ul> <p>This course is a PRACE training course.</p>", "markdown_description": "GPU-accelerated computing drives current scientific research. Writing fast numeric algorithms for GPUs offers high application performance by offloading compute-intensive portions of the code to an NVIDIA GPU. The course will cover basic aspects of GPU architectures and programming. Focus is on the usage of the parallel programming language CUDA C/C++ which allows maximum control of NVIDIA GPU hardware. Examples of increasing complexity will be used to demonstrate optimization and tuning of scientific applications.\n\nTopics covered will include:\n\n  * Introduction to GPU/Parallel computing\n  * Programming model CUDA\n  * GPU libraries like CuBLAS and CuFFT\n  * Tools for debugging and profiling\n  * Performance optimizations\n  * Advanced GPU programming model\n  * CUDA Fortran in a nutshell\n\n\n\nThis course is a PRACE training course.", "summary": "GPU-accelerated computing drives current scientific research. Writing fast numeric algorithms for GPUs offers high application..."}]}]